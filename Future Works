Self-Collision
Why Rnn? -> Skills
Limited Signers/Clothes -> Add Augmentation
Add noise to pb

Loss_Pose = KL + Pose + Orientation + Velocity
Lose_Finger = KL + Bone direction + relative distance + Velocity

$$ Quaternion

def compute_palm_quaternion(wrist, little_root, index_root, eps=1e-8):
    """
    Compute palm orientation quaternion from wrist, little finger root, and index finger root positions.
    Args:
        wrist (torch.Tensor): [..., 3] wrist position
        little_root (torch.Tensor): [..., 3] little finger root position
        index_root (torch.Tensor): [..., 3] index finger root position
        eps (float): Small value to avoid division by zero
    Returns:
        quat (torch.Tensor): [..., 4] quaternion (w, x, y, z)
    """
    # Compute local axes (right, forward, up)
    right = F.normalize(index_root - wrist, dim=-1, eps=eps)  # X-axis
    temp_forward = little_root - wrist
    forward = F.normalize(temp_forward - torch.sum(temp_forward * right, dim=-1, keepdim=True) * right, 
                          dim=-1, eps=eps)  # Y-axis (orthogonal to X)
    up = torch.cross(right, forward, dim=-1)  # Z-axis

    # Construct rotation matrix [X, Y, Z]
    rot_matrix = torch.stack([right, forward, up], dim=-1)  # [..., 3, 3]

    # Convert rotation matrix to quaternion
    # Source: https://github.com/facebookresearch/pytorch3d/blob/main/pytorch3d/transforms/rotation_conversions.py
    def _matrix_to_quaternion(rot_matrix):
        batch_dim = rot_matrix.shape[:-2]
        m00, m01, m02 = rot_matrix[..., 0, 0], rot_matrix[..., 0, 1], rot_matrix[..., 0, 2]
        m10, m11, m12 = rot_matrix[..., 1, 0], rot_matrix[..., 1, 1], rot_matrix[..., 1, 2]
        m20, m21, m22 = rot_matrix[..., 2, 0], rot_matrix[..., 2, 1], rot_matrix[..., 2, 2]

        # Symmetric matrix K
        K = torch.stack([
            torch.stack([m00 - m11 - m22, torch.zeros_like(m00), torch.zeros_like(m00), torch.zeros_like(m00)], dim=-1),
            torch.stack([m01 + m10, m11 - m00 - m22, torch.zeros_like(m00), torch.zeros_like(m00)], dim=-1),
            torch.stack([m02 + m20, m12 + m21, m22 - m00 - m11, torch.zeros_like(m00)], dim=-1),
            torch.stack([m21 - m12, m02 - m20, m10 - m01, m00 + m11 + m22], dim=-1)
        ], dim=-2)

        # Find largest diagonal element to avoid numerical instability
        K = K / 3.0
        _, vectors = torch.linalg.eigh(K)
        quat = vectors[..., -1]  # Take eigenvector for largest eigenvalue
        return F.normalize(quat, dim=-1, eps=eps)

    quat = _matrix_to_quaternion(rot_matrix)
    return quat  # [..., 4] (w, x, y, z)

$$ Finger Similarity
import torch

def build_palm_coordinate_frame(joint_positions, palm_indices):
    """
    Compute a palm-local coordinate frame for each hand in the batch.
    Args:
        joint_positions: (B, N, 3) tensor of 3D joint positions.
        palm_indices: List of indices marking palm joints (e.g., [0, 1, 2, 3]).
    Returns:
        R: (B, 3, 3) rotation matrices (local frame axes as columns).
        t: (B, 3) palm center (translation).
    """
    # Compute palm center (mean of palm joints)
    t = torch.mean(joint_positions[:, palm_indices, :], dim=1)  # (B, 3)

    # Define palm axes (X: palm to middle finger base, Y: palm normal, Z: cross(X,Y))
    middle_finger_base = joint_positions[:, palm_indices[-1], :]  # (B, 3)
    x_axis = middle_finger_base - t  # (B, 3)
    x_axis = x_axis / torch.norm(x_axis, dim=1, keepdim=True)  # Normalize

    # Approximate palm plane normal (Y-axis) using PCA on palm joints
    palm_joints = joint_positions[:, palm_indices, :] - t.unsqueeze(1)  # (B, num_palm_joints, 3)
    _, _, V = torch.pca_lowrank(palm_joints)  # V is (B, 3, 3)
    y_axis = V[:, :, 0]  # First principal component (rough palm normal)
    y_axis = y_axis / torch.norm(y_axis, dim=1, keepdim=True)

    # Ensure orthogonality via cross product
    z_axis = torch.cross(x_axis, y_axis, dim=1)  # (B, 3)
    z_axis = z_axis / torch.norm(z_axis, dim=1, keepdim=True)
    y_axis = torch.cross(z_axis, x_axis, dim=1)  # Recompute Y for orthogonality

    # Rotation matrix (local frame axes as columns)
    R = torch.stack([x_axis, y_axis, z_axis], dim=2)  # (B, 3, 3)

    return R, t

def transform_to_palm_frame(joint_positions, R, t):
    """
    Transform joint positions to palm-relative coordinates.
    Args:
        joint_positions: (B, N, 3) tensor of global joint positions.
        R: (B, 3, 3) rotation matrices (local frame axes).
        t: (B, 3) palm center (translation).
    Returns:
        local_positions: (B, N, 3) joint positions in palm frame.
    """
    # Subtract palm center and rotate into local frame
    local_positions = joint_positions - t.unsqueeze(1)  # (B, N, 3)
    local_positions = torch.bmm(local_positions, R)  # (B, N, 3)
    return local_positions

# Example Usage
batch_size = 2
num_joints = 21  # Human hand typically has 21 joints
palm_indices = [0, 1, 2, 3]  # Example palm joint indices

# Random joint positions (simulated data)
joint_positions = torch.randn(batch_size, num_joints, 3)

# Build palm frame and transform joints
R, t = build_palm_coordinate_frame(joint_positions, palm_indices)
local_joint_positions = transform_to_palm_frame(joint_positions, R, t)

print("Global joint positions (sample 0):\n", joint_positions[0])
print("Palm-local joint positions (sample 0):\n", local_joint_positions[0])

# During training:
human_R, human_t = build_palm_coordinate_frame(human_joints, palm_indices)
robot_R, robot_t = build_palm_coordinate_frame(robot_joints, palm_indices)

human_local = transform_to_palm_frame(human_joints, human_R, human_t)
robot_local = transform_to_palm_frame(robot_joints, robot_R, robot_t)

# Compute losses on local frames (e.g., bone direction loss)
human_bones = human_local[:, finger_joints] - human_local[:, base_joints]
robot_bones = robot_local[:, finger_joints] - robot_local[:, base_joints]
loss = 1 - torch.cosine_similarity(human_bones, robot_bones, dim=-1).mean()